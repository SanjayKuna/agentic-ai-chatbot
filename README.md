This project is a sophisticated AI Research Assistant designed to deliver accurate, up-to-date answers to user queries through a simple web interface. At its core, the application leverages a powerful two-agent system built with Microsoft's AutoGen framework, creating a robust and reliable workflow for information retrieval and synthesis. This multi-agent architecture moves beyond traditional chatbots, enabling a more dynamic and intelligent process where tasks are clearly delegated and executed. The primary "worker" is the ResearchAssistant, an advanced AI agent tasked with understanding a user's question, performing live web searches, and composing a final, well-structured response. This process is powered by several key technologies that work in concert. The backend server is built with Flask, a lightweight Python web framework that efficiently manages user requests and orchestrates the AI workflow. For live data retrieval, the assistant is equipped with a tool that connects to the Tavily API, ensuring the information it gathers is current and not limited to the LLM's static training data. This is a crucial feature that allows the system to provide relevant answers on recent events and evolving topics. The entire system's intelligence is driven by a Large Language Model (like Llama 3) running on Groq's high-speed inference engine, which allows for near-instantaneous processing and response generation, providing a smooth, real-time user experience. A key architectural feature is the use of a UserProxyAgent which acts as a secure executor for the web_search tool, creating a clear separation between the AI's reasoning and its ability to interact with the external world. The final, verified answer is then sent back to a clean, user-friendly frontend built with HTML, CSS, and JavaScript, providing a seamless experience. This powerful combination of an agentic framework, a live search API, and a high-performance LLM makes the project a powerful and modern example of a Retrieval-Augmented Generation (RAG) system, capable of delivering trustworthy and well-researched answers on demand.
